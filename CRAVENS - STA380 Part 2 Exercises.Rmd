---
title: 'CRAVENS - Part 2 Excercies'
author: "Conoly Cravens (mcc4443)"
date: "8/3/2021"
output:
  word_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# **Question 1** Visual Story Telling Part 1: *Green Buildings*



# **Question 2** Visual Story Telling Part 2: *Flights at ABIA*



# **Question 3** Portfolio Modeling

```{r, document setup, echo=FALSE, include=FALSE}
rm(list = ls())
library(mosaic)
library(quantmod)
library(foreach)
library(formattable)
```

We assessed three different portfolios VaR:

* Income Focused Portfolio
- A portfolio made up of *5 EFTs* with high dividend payout. 
* Tech Portfolio
- A portfolio made up of *5 EFTs* focused on technology equities.
- As a reminder, the tech industry is very volatile.
* Balanced Portfolio 
- A portfolio made up of *7 EFTs* focused on balanced and diversification. 

```{r,Portfolio Fixed Values, echo=FALSE, include=FALSE}
n_days = 20
initial_wealth = 100000
```

## Income Focused Portfolio
The five EFTs: 

* **SDIV** {Global Equities} - offer exposure to a basket of dividend-paying equities on  a global scale
* **YLD** {High Yield Bonds} - provide “current income with diversified risk” by investing in companies with a “defensive quality bias.”
* **IJJ** {Mid Cap Value Equities} - exposure to mid-cap stocks that exhibit value characteristics and fine tune their domestic equity exposure
* **REZ** {Real Estate} – known for distributing 90% of their income to investors
* **SPYD** {Large Cap Blend Equities} – top 80 dividend-yielding companies in the S&P 500 

```{r,Income Bootstrap, echo=FALSE, include=FALSE}
# Import EFTs in income portfolio
incomeStocks = c("SDIV","YLD","IJJ","REZ","SPYD")
getSymbols(incomeStocks,
           from = "2016-08-01",
           to= "2021-07-30")

# Adjust all stocks in income driven portfolio and add an 'a' on the end
for(ticker in incomeStocks) {
  expr = paste0(ticker, "a = adjustOHLC(", ticker, ")")
  eval(parse(text=expr))}

# Combine all the returns in a matrix
income_returns = cbind(ClCl(SDIVa),
                       ClCl(YLDa),
                       ClCl(IJJa),
                       ClCl(REZa),
                       ClCl(SPYDa))
income_returns = as.matrix(na.omit(income_returns))

# Bootstrap 5,000 different 4-week trading periods:
set.seed(100)
sim1 = foreach(i=1:5000, .combine='rbind') %do% {
  total_wealth = initial_wealth
  weights = c(0.2, 0.2, 0.2, 0.2, 0.2)
  holdings = weights * total_wealth
  wealthtrackerIncome = rep(0, n_days)
  for(today in 1:n_days) {
    returnI.today = resample(income_returns, 1, orig.ids=FALSE)
    holdings = holdings + holdings*returnI.today
    total_wealth = sum(holdings)
    wealthtrackerIncome[today] = total_wealth
    holdings = weights * total_wealth   #rebalance!
  }
  wealthtrackerIncome
}

```


A quick glimpse of the profit/loss histogram for the 5,000 bootstrap samples:

```{r,Income profit loss, echo=FALSE}
hist(sim1[,n_days]- initial_wealth, breaks=30,
     main = 'Profit/ Loss Histogram',
     xlab = 'Profit/ Loss',
     col = 'green')
```
Using the 5,000 bootstrap samples, we estimate the the 4-week value at risk for the *income driven portfolio* at the 5% level to: 

```{r,Income VaR, echo=FALSE}
# 5% value at risk:
incomeVaR = quantile(sim1[,n_days]- initial_wealth, prob=0.05)
#Format VaR
incomeVaR.format = paste0("$", formatC(as.numeric(abs(incomeVaR)), format="f", digits=0, big.mark=","))
incomeVaR.format
```
## Tech Portfolio

* **SPYG** {Large Gap Growth Equities} - over 300 holdings and exposure is tilted most heavily towards technology
* **QQQ** {Large Gap Growth Equities} - useful as part of a buy-and-hold approach for investors looking to maintain a tilt towards the potentially volatile tech sector
* **XLK** {Technology Equities} - it invests in companies from all across the technology sector
* **TDIV** {Technology Equities} - First Trust NASDAQ Technology Dividend Index Fund
* **FXL** {Technology Equities} - looking for a more qualitative approach to the tech sector

```{r,Tech Bootstrap, echo=FALSE, include=FALSE}
#Import EFTs in tech portfolio
techStocks = c("SPYG","QQQ","XLK","TDIV","FXL")
getSymbols(techStocks,
           from = "2016-08-01",
           to= "2021-07-30")


# Adjust all stocks in the tech  portfolio and add an 'a' on the end
for(ticker in techStocks) {
  expr = paste0(ticker, "a = adjustOHLC(", ticker, ")")
  eval(parse(text=expr))}

# Combine all the returns in a matrix
tech_returns = cbind(ClCl(SPYGa),
                     ClCl(QQQa),
                     ClCl(XLKa),
                     ClCl(TDIVa),
                     ClCl(FXLa))

tech_returns = as.matrix(na.omit(tech_returns))

# Bootstrap 5,000 samples of 4-week trading periods
set.seed(500)
sim3 = foreach(i=1:5000, .combine='rbind') %do% {
  total_wealth = initial_wealth
  weights = c(0.2,0.2,0.2,0.2,0.2)
  holdings = weights * total_wealth
  wealthtrackerTech= rep(0, n_days)
  for(today in 1:n_days) {
    returnT.today = resample(tech_returns, 1, orig.ids=FALSE)
    holdings = holdings + holdings*returnT.today
    total_wealth = sum(holdings)
    wealthtrackerTech[today] = total_wealth
    holdings = weights * total_wealth
  }
  wealthtrackerTech
}
```

A quick glimpse of the profit/loss histogram for the 5,000 bootstrap samples {note a couple of huge wins since the tech industry is so volitle}:

```{r,tech profit loss, echo=FALSE}
hist(sim3[,n_days]- initial_wealth, breaks=30,
     main = 'Profit/ Loss Histogram',
     xlab = 'Profit/ Loss',
     col = 'blue')
```

Using the 5,000 bootstrap samples, we estimate the the 4-week value at risk for the *tech portfolio* at the 5% level to:

```{r,tech VaR, echo=FALSE}
# 5% value at risk:
techVaR = quantile(sim3[,n_days]- initial_wealth, prob=0.05)
# Format VaR
techVaR.format = paste0("$", formatC(as.numeric(abs(techVaR)), format="f", digits=0, big.mark=","))
techVaR.format
```

## Balanced Portfolio

* **RSP** {Large Cap Blend Equities} - considerably more balanced than other alternatives such as SPY, and a methodology that some investors believe will add value over the long haul
* **BSV** {Total Bond Markets} - great safe haven to park assets in volatile markets
* **RYT** {Technology Equities} - exposure that is considerably more balanced
* **SPEM** {Emerging Market Equities} - well-diversified option for long-term investors building a balanced portfolio
* **SCHF** {Foreign Large Cap Equities} - close to 1,000 individual holdings, this ETF brings immediate diversification 
* **VXF** {All Cap Equities} - extremely diversified in small and mid caps
* **AOA** {Diversified Portfolio} - seeking an aggressive strategy that tilts towards equities and away from fixed income

```{r,Balanced Bootstrap, echo=FALSE, include=FALSE}
# Import the 7 EFTs in the balanced portfolio
balancedStocks = c("RSP","BSV","RYT","SPEM","SCHF","VXF","AOA")
getSymbols(balancedStocks,
           from = "2016-08-01",
           to= "2021-07-30")


# Adjust all EFTs
for(ticker in balancedStocks) {
  expr = paste0(ticker, "a = adjustOHLC(", ticker, ")")
  eval(parse(text=expr))}

# Combine all the returns in a matrix
balanced_returns = cbind(ClCl(AOAa),
                         ClCl(BSVa),
                         ClCl(RSPa),
                         ClCl(RYTa),
                         ClCl(SCHFa),
                         ClCl(SPEMa),
                         ClCl(VXFa))
  
balanced_returns = as.matrix(na.omit(balanced_returns))

# Bootstrap 5,000 different 4 week trading periods
initial_wealth = 100000
set.seed(100)
sim2 = foreach(i=1:5000, .combine='rbind') %do% {
  total_wealth = initial_wealth
  weights = c(1/7,1/7,1/7,1/7,1/7,1/7,1/7)
  holdings = weights * total_wealth
  n_days = 10
  wealthtrackerBalanced = rep(0, n_days)
  for(today in 1:n_days) {
    returnB.today = resample(balanced_returns, 1, orig.ids=FALSE)
    holdings = holdings + holdings*returnB.today
    total_wealth = sum(holdings)
    wealthtrackerBalanced[today] = total_wealth
    holdings = weights * total_wealth   #rebalance
  }
  wealthtrackerBalanced
}
```

A quick glimpse of the profit/loss histogram for the 5,000 bootstrap samples:

```{r,Balanced profit loss, echo=FALSE}
hist(sim2[,n_days]- initial_wealth, breaks=30,
     main = 'Profit/ Loss Histogram',
     xlab = 'Profit/ Loss',
     col = 'red')
```

Using the 5,000 bootstrap samples, we estimate the the 4-week value at risk for the *Balanced portfolio* at the 5% level to:

```{r,Balanced VaR, echo=FALSE}
# 5% value at risk:
BalancedVaR = quantile(sim2[,n_days]- initial_wealth, prob=0.05)
# Format VaR
BalancedVaR.format = paste0("$", formatC(as.numeric(abs(BalancedVaR)), format="f", digits=0, big.mark=","))
BalancedVaR.format
```
So in summary, we have three portfolios. One focused on dividend payout, one focused on tech (volatile industry), and another one with a well balanced portfolio. For each portfolio, we estimated the 4-week VaR at the 5% level:

```{r, Portfolio summary table, echo=FALSE}
data.frame('Portfolio' = c('Income-Drive','Tech','Balanced'),
                     'VaR' = c(incomeVaR.format,techVaR.format,BalancedVaR.format))

```

To no surprise, the balanced portfolio has the lowest amount of risk for a 4-week (20 trading day) period. Tech and income-driven turn out to have about the same amount of risk. 

# **Question 4** Market Segmentation

FOR: NutrientH20 Executives
OBJECTIVE: Identify market segments that appear in your social-media audience
```{r, Q4 Document setup, echo=FALSE,include=FALSE}
rm(list = ls())
library(ggplot2)
library(formattable)
library(cluster)
library(foreach)
library(data.table)

setwd("~/SUMMER 2021/STA 380 - Intro to Machine Learning/Exercies pt. 2")
#Read Data in
rawData = read.csv('social_marketing.txt',sep = ',',header = TRUE,row.names=1)

social = rawData
#Combine Spam & Adult (most likely bots)
social$bot = social$spam + social$adult

#Combine uncategorized & chatter since annotators used interchangeably
social$unknown = social$uncategorized + social$chatter

#Deselect columns
social = social[,-c(1,5,35,36)]
```

## Methodology: Kmeans Clustering
After some data exploration and fitting a variety of models, we determined that K-means clustering was an effective (and efficient) way to determine market segments.

### Determining the Optimal Number of Clusters (k)

```{r, Q4 Kmeans, echo=FALSE, include=FALSE}
# Center and scale the data
socialScaled = scale(social, center=TRUE, scale=TRUE)

# Extract the centers and scales from the rescaled data (which are named attributes)
mu = attr(socialScaled,"scaled:center")
sigma = attr(socialScaled,"scaled:scale")

set.seed(5)
k_grid = seq(2,30, by = 1)
SSE_grid = foreach(k=k_grid,  .combine='c') %do% {
  cluster_k = kmeans(socialScaled,k,nstart=50)
  cluster_k$tot.withinss
}
```

```{r, Q4 Kmeans Elbow Plot, echo=FALSE}
plot(x=k_grid, y= SSE_grid,col=ifelse(k_grid==10, "red", "grey24"),
     pch = 16, main='Elbow Plot',
     xlab = '# of clusters (k)',
     ylab = 'Error (SSE)')
```

From the elbox plot, we determined that **10** clusters optimizes the bias-variance trade off in our error (slope from 10 -> 11 is less steap than the slope from 9 -> 10). 

## Result
After dividing our followers into 10 segments, we get the following table of centers (conditional formatted to highlight the factors that each cluster scored well in).

```{r, Q4 Kmeans Centers, echo=FALSE}
set.seed(5)
#Run kmeans model
clusters = kmeans(socialScaled, 10, nstart=50,iter.max = 20)

#Clean up centers table
centers = transpose(data.frame(clusters$centers))
rownames(centers) = colnames(data.frame(clusters$centers))
colnames(centers) = rownames(data.frame(clusters$centers))

#Conditional Format
centers = formattable(centers, lapply(1:ncol(centers), function(col) {
  area(col, row = -1) ~ color_tile("white", "lightgreen")
}))
centers
```

## Cluster Analysis

### Cluster 1: Working Professionals
Cluster one had high scores in *travel*, *politics*, and *computers*, and medium scores in business, small business, and news. Based on these characteristics, we classify these are working professionals. 

### Cluster 2: Middle Age Men
Cluster two had high scores in *politics*, *news*, and *automative*, and medium scores in sports fandom and outdoors. Based on these characteristics, we classify these are middle age men.


### Cluster 3: Uncharacterized 
Cluster three had all negative scores, meaning no category stood out. This is the cluster of people we could not classify. 

### Cluster 4: Parents 
Cluster four had high scores in *family*, *religion*, *parenting*, *school*, *sports fandom*, and *food*. Based on these characteristics, we classify this segment as parents. 

### Cluster 5: BOTs 
Cluster five are the bots that were not initially filtered out.

### Cluster 6: Artists
Cluster six had high scores in *tv film* and *art*, and medium scores in music, craft, and small businesses. Based on these characteristics, we classify these as artists.

### Cluster 7: Young Women 
Cluster seven had high scores in *cooking*, *beauty*, and *fashion*, and medium scores in photo sharing and music. Based on these characteristics, we classify these as young women

### Cluster 8: College Students
Cluster eight had high scores in *online gaming*, *college university*, and *sports playing*. Based on these characteristics, we classify these as college students.

### Cluster 9: Middle Aged Women Active on Computers 
Cluster nine had high scores in *photo sharing*, *shopping*, and *unknown (combination of chatter and uncategorized*. Based on these characteristics, we classify these as middle age women active on their computers.

### Cluster 10: Fitness Enthusiest
Cluster ten had high scores in *health nutrition*, *outdoors*, and *personal fitness*, and medium scores in food, cooking, and eco. Based on these characteristics, we classify this cluster as fitness enthusiast.

To better picture these clusters, I put together a plot for each cluster (excluding Bots & Uncharacterized) showing dots for different users along the scale of two primary factors. Each dot is colored in with the cluster. You will see for each graph, the cluster being highlighted dominates the graph!

```{r, Q4 Cluster Plots , echo=FALSE, fig.show="hold", out.width="25%"}
#Qplot for each cluster...

qplot(travel, computers, data=social, color=factor(clusters$cluster), main = 'Cluster 1: Working Professionals')

qplot(news, automotive, data=social, color=factor(clusters$cluster), main = 'Cluster 2: Middle Age Men')

qplot(parenting, family, data=social, color=factor(clusters$cluster), main = 'Cluster 4: Parents')

qplot(tv_film, art, data=social, color=factor(clusters$cluster), main = 'Cluster 6: Artists')

qplot(beauty, fashion, data=social, color=factor(clusters$cluster), main = 'Cluster 7: Young Women ')

qplot(online_gaming, college_uni, data=social, color=factor(clusters$cluster), main = 'Cluster 8: College Students')

qplot(shopping, photo_sharing, data=social, color=factor(clusters$cluster), main = 'Cluster 9: Middle Aged Women Active on Computers')

qplot(health_nutrition, personal_fitness, data=social, color=factor(clusters$cluster), main = 'Cluster 10: Fitness Enthusiest')
```

## Summary
We saw a total of 10 different clusters, all with different sizes:

```{r, Q4 Kmeans Final Table, echo=FALSE}
#Create summary dataframe
data.frame('Cluster' = 1:10,
           'Characteristic' = c('Working Professionals',
                                'Middle Age Men','Uncharacterized',
                                'Parents', 'Bots','Artists',
                                'Young Women', 'College Students',
                                'Middle age women on computers',
                                'Fitness Enthusiest'),
           'Cluster Size' = clusters$size,
           'Percent of Audience' = round(clusters$size/7882*100))
```

While we would ideally trim down the uncharacterized users to a unique group, increasing the number of clusters makes other categories too small (less than 2%) and therefore take away from the overall effectivness of market segmentation for business implenetation. 

# **Question 5** Author Attribution



# **Question 6 ** Association Rule Mining

